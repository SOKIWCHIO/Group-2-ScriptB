# ä¸ç¡®å®šæ€§ä¼°è®¡ä¸»é¢˜èšç±»é¡¹ç›®
# Uncertainty Estimation Topic Clustering Project

LinkedIn å’Œ Reddit æ”¶é›†å…³äº"ä¸ç¡®å®šæ€§ä¼°è®¡"çš„å¸–å­ï¼Œç„¶åç”¨èšç±»ç®—æ³•åˆ†æå‡ºä¸åŒçš„ç ”ç©¶ä¸»é¢˜ã€‚
LinkedIn and Reddit collect posts related to "uncertainty estimation", and then use clustering algorithms to analyze different research topics.

## 0.æ–‡ä»¶ç»“æ„
## 0.File Structure
Group_2_Script_B
â”‚
â”œâ”€â”€ requirements.txt                           # Pythonä¾èµ–åŒ…åˆ—è¡¨ | Python Dependencies List
â”œâ”€â”€ linkedin_cookies.json                      # LinkedInç™»å½•å‡­è¯ | LinkedIn Login Credentials
â”œâ”€â”€ READ.md                                    # é¡¹ç›®è¯´æ˜æ–‡æ¡£ | Project Documentation
â”‚
â”œâ”€â”€ pipeline_0_linkedin_cookie.py              # Step 0: è·å–LinkedIn Cookies | Get LinkedIn Cookies
â”œâ”€â”€ pipeline_1_crawler_linkedin.py             # Step 1a: LinkedInå¸–å­é‡‡é›† | LinkedIn Post Scraper
â”œâ”€â”€ pipeline_1_crawler_Reddit.py               # Step 1b: Redditå¸–å­é‡‡é›† | Reddit Post Scraper
â”œâ”€â”€ pipeline_2_semantic_filter.py              # Step 2: è¯­ä¹‰è¿‡æ»¤å™¨ | Semantic Filter
â”œâ”€â”€ pipeline_3_cluster.py                      # Step 3a: èšç±»åˆ†æ | Clustering Analysis
â”œâ”€â”€ pipeline_3_cluster_print.py                # Step 3b: èšç±»å¯è§†åŒ– | Clustering Visualization
â”‚
â”œâ”€â”€ linkedin_posts/                            # LinkedInåŸå§‹å¸–å­ | Raw LinkedIn Posts
â”‚   â”œâ”€â”€ a1b2c3d4e5f6.txt                      # å¸–å­1 | Post 1
â”‚   â”œâ”€â”€ f6e5d4c3b2a1.txt                      # å¸–å­2 | Post 2
â”‚   â””â”€â”€ ... (500+ files)                      # æ•°ç™¾ä¸ªå¸–å­æ–‡ä»¶ | Hundreds of post files
â”‚
â”œâ”€â”€ Reddit_posts/                              # Reddit/StackExchangeåŸå§‹å¸–å­ | Raw Reddit/StackExchange Posts
â”‚   â”œâ”€â”€ uncertainty_in_machine_learning.txt   # Redditå¸–å­ç¤ºä¾‹ | Reddit post example
â”‚   â”œâ”€â”€ model_uncertainty_quantification.txt  # StackExchangeé—®ç­”ç¤ºä¾‹ | StackExchange Q&A example
â”‚   â””â”€â”€ ... (200-500 files)                   # æ•°ç™¾ä¸ªå¸–å­æ–‡ä»¶ | Hundreds of post files
â”‚
â”œâ”€â”€ filter_stats/                              # è¿‡æ»¤ç»Ÿè®¡æ•°æ® | Filtering Statistics
â”‚   â”œâ”€â”€ filtering_analysis.png                # è¿‡æ»¤æ•ˆæœå¯è§†åŒ–å›¾ | Filtering Effect Visualization
â”‚   â”œâ”€â”€ all_scores.csv                        # æ‰€æœ‰å¸–å­è¯„åˆ†ï¼ˆè¿‡æ»¤å‰ï¼‰| All Posts Scores (Before Filter)
â”‚   â”œâ”€â”€ filtered_scores.csv                   # é€šè¿‡è¿‡æ»¤çš„å¸–å­è¯„åˆ† | Filtered Posts Scores
â”‚   â””â”€â”€ filter_summary.json                   # è¿‡æ»¤ç»Ÿè®¡æ‘˜è¦ | Filter Summary Statistics
â”‚
â”œâ”€â”€ filtered_posts/                            # è¿‡æ»¤åçš„é«˜è´¨é‡å¸–å­ | Filtered High-Quality Posts
â”‚   â”œâ”€â”€ a1b2c3d4e5f6.txt                      # é«˜è´¨é‡å¸–å­1 | High-quality post 1
â”‚   â”œâ”€â”€ i9j0k1l2m3n4.txt                      # é«˜è´¨é‡å¸–å­2 | High-quality post 2
â”‚   â””â”€â”€ ... (100-300 files)                   # è¿‡æ»¤åä¿ç•™çš„å¸–å­ | Posts retained after filtering
â”‚
â”œâ”€â”€ cluster_output/                            # èšç±»åˆ†æç»“æœ | Clustering Analysis Results
â”‚   â”œâ”€â”€ embeddings.pkl                        # æ–‡æœ¬å‘é‡æ•°æ®ï¼ˆ3072ç»´ï¼‰| Text Embeddings (3072-dim)
â”‚   â”‚
â”‚   â”œâ”€â”€ hdbscan_umap2d.png                    # HDBSCANå¯è§†åŒ–å›¾ | HDBSCAN Visualization
â”‚   â”œâ”€â”€ HDBSCAN_clusters.csv                  # HDBSCANèšç±»æ˜ å°„è¡¨ | HDBSCAN Cluster Mapping
â”‚   â”œâ”€â”€ HDBSCAN_representatives.txt           # HDBSCANç°‡æ‘˜è¦ï¼ˆå…³é”®è¯+ä»£è¡¨æ–‡æœ¬ï¼‰| HDBSCAN Cluster Summary
â”‚   â”œâ”€â”€ HDBSCAN_meta.json                     # HDBSCANå®Œæ•´å…ƒæ•°æ® | HDBSCAN Full Metadata
â”‚   â”‚
â”‚   â”œâ”€â”€ kmeans_k2_umap2d.png                  # KMeanså¯è§†åŒ–å›¾ï¼ˆK=2ï¼‰| KMeans Visualization (K=2)
â”‚   â”œâ”€â”€ KMeans_K2_clusters.csv                # KMeansèšç±»æ˜ å°„è¡¨ | KMeans Cluster Mapping
â”‚   â”œâ”€â”€ KMeans_K2_representatives.txt         # KMeansç°‡æ‘˜è¦ | KMeans Cluster Summary
â”‚   â””â”€â”€ KMeans_K2_meta.json                   # KMeanså®Œæ•´å…ƒæ•°æ® | KMeans Full Metadata
â”‚
â””â”€â”€ cluster_visualizations/                    # èšç±»å¤šç»´åº¦å¯è§†åŒ– | Multi-dimensional Cluster Visualizations
    â”œâ”€â”€ HDBSCAN_pca2d.png                     # HDBSCAN-PCAé™ç»´å›¾ | HDBSCAN-PCA Dimensionality Reduction
    â”œâ”€â”€ HDBSCAN_tsne.png                      # HDBSCAN-tSNEé™ç»´å›¾ | HDBSCAN-tSNE Dimensionality Reduction
    â”œâ”€â”€ HDBSCAN_umap.png                      # HDBSCAN-UMAPé™ç»´å›¾ | HDBSCAN-UMAP Dimensionality Reduction
    â”œâ”€â”€ KMeans_K2_pca2d.png                   # KMeans-PCAé™ç»´å›¾ | KMeans-PCA Dimensionality Reduction
    â”œâ”€â”€ KMeans_K2_tsne.png                    # KMeans-tSNEé™ç»´å›¾ | KMeans-tSNE Dimensionality Reduction
    â””â”€â”€ KMeans_K2_umap.png                    # KMeans-UMAPé™ç»´å›¾ | KMeans-UMAP Dimensionality Reduction


### 1. å®‰è£…ä¾èµ– Install dependencies
```bash
pip install -r requirements.txt
```

### 2. è¿è¡Œæµç¨‹ Operation process
```bash
# ç¬¬ 1 æ­¥ï¼šçˆ¬æ•°æ®
# Step 1: Collect Data.
# The data is stored in "linkedin_posts".
python pipeline_1_crawler_linkedin.py
# The data is stored in "Reddit_posts".
python pipeline_1_crawler_Reddit.py

# ç¬¬ 2 æ­¥ï¼šè¿‡æ»¤æ•°æ®
# Step 2: Filter the data
#The data is input from the "linkedin_posts" and "Reddit_posts" sources and is then output to the "filtered_posts" destination.
#The "filter_stats" folder contains the filtering statistics charts.
python pipeline_2_semantic_filter.py

# ç¬¬ 3 æ­¥ï¼šèšç±»
# Step 3: Clustering
#Input is "filtered_posts", and output is "cluster_output".
python pipeline_3_cluster.py

# ç¬¬ 4 æ­¥ï¼šç”Ÿæˆå›¾è¡¨
# Step 4: Generate Charts
# The generated graph is in the "cluster_visualizations" folder.
python pipeline_4_visualizations.py
```

### Pipeline 1: æ•°æ®é‡‡é›† ğŸ•·ï¸
### Pipeline 1: Data Collection
**Function**: Scrape posts related to "uncertainty estimation" from LinkedIn and Reddit
- Need: Google Custom Search API,SEARCH_ENGINE_ID,linkedin account.
- Use the script "preliminary_pipeline_0_linkedin_cookie.py" to obtain the LinkedIn account. JSON file
# Enter the API key here:
```bash
GOOGLE_API_KEY = "-"   # Google Custom Search API Key
SEARCH_ENGINE_ID = "-" # Google Custom Search Engine ID
```
- `pipeline_1_crawler_linkedin.py`
Need: Reddit API credentials.
- `pipeline_1_crawler_Reddit.py`
**output**ï¼š
- `linkedin_posts/` - 451 .txt
- `Reddit_posts/` - 1068 .txt

### Pipeline 2: è¯­ä¹‰è¿‡æ»¤
### Pipeline 2: Semantic Filtering
**Function**:
From 1519 posts, filter out the truly relevant ones (eliminating chats, advertisements, etc.)
- Use an AI model to calculate the similarity between each post and the "uncertainty estimation" topic
- Only retain posts with a similarity score greater than 30 points
**output**ï¼š
- `filtered_posts/` - 532 high-quality posts
- `filter_stats/` - Filter statistics charts
**setting**ï¼š
```python
# If you want stricter filtering, change this number.
# The default is 30. Changing it to 40 will make the filtering even stricter.
THRESHOLD = 30.0  
```

### Pipeline 3: èšç±»åˆ†æ 
### Pipeline 3: Cluster Analysis
**Function**:
Automatically categorize 532 posts into different topics
- OpenAI API: Convert text into numbers (embedding)
- UMAP: Dimensionality reduction (reduce from 3072 dimensions to 50 dimensions)
- HDBSCAN: Automatically identify 16 topics
- Need:OpenAI API
# Enter the API key here:
```bash
export OPENAI_API_KEY="ä½ çš„å¯†é’¥"
```
**output**
- `cluster_output/HDBSCAN_clusters.csv` - Which topic each post belongs to
- `cluster_output/HDBSCAN_representatives.txt` - Keywords for each topic and representative posts
- `cluster_output/hdbscan_umap2d.png` - Visualization of clustering results

### Pipeline 4: å¯è§†åŒ– 
### Pipeline 4: Visualization
cluster_visualizations/                    # èšç±»å¤šç»´åº¦å¯è§†åŒ– | Multi-dimensional Cluster Visualizations
    â”œâ”€â”€ HDBSCAN_pca2d.png                     # HDBSCAN-PCAé™ç»´å›¾ | HDBSCAN-PCA Dimensionality Reduction
    â”œâ”€â”€ HDBSCAN_tsne.png                      # HDBSCAN-tSNEé™ç»´å›¾ | HDBSCAN-tSNE Dimensionality Reduction
    â”œâ”€â”€ HDBSCAN_umap.png                      # HDBSCAN-UMAPé™ç»´å›¾ | HDBSCAN-UMAP Dimensionality Reduction
    â”œâ”€â”€ KMeans_K2_pca2d.png                   # KMeans-PCAé™ç»´å›¾ | KMeans-PCA Dimensionality Reduction
    â”œâ”€â”€ KMeans_K2_tsne.png                    # KMeans-tSNEé™ç»´å›¾ | KMeans-tSNE Dimensionality Reduction
    â””â”€â”€ KMeans_K2_umap.png                    # KMeans-UMAPé™ç»´å›¾ | KMeans-UMAP Dimensionality Reduction



