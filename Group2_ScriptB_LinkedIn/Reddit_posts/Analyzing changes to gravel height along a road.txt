Source: Reddit/datascience
URL: https://reddit.com/r/datascience/comments/1i6qa6u/analyzing_changes_to_gravel_height_along_a_road/
Title: Analyzing changes to gravel height along a road

Content:
I’m working with a dataset that measures the height of gravel along a 50 km stretch of road at 10-meter intervals. I have two measurements:

Baseline height: The original height of the gravel.

New height: A more recent measurement showing how the gravel has decreased over time.

This gives me the difference in height at various points along the road. I’d like to model this data to understand and predict gravel depletion. 

Here’s what I’m considering:Identifying trends or patterns in gravel loss (e.g., areas with more significant depletion).

Using interpolation to estimate gravel heights at points where measurements are missing.

Exploring possible environmental factors that could influence depletion (e.g., road curvature, slope, or proximity to towns).

However, I’m not entirely sure how to approach this analysis. Some questions I have:

What are the best methods to visualize and analyze this type of spatial data?

Are there statistical or machine learning models particularly suited for this?

If I want to predict future gravel heights based on the current trend, what techniques should I look into? Any advice, suggestions, or resources would be greatly appreciated!

Comments:
- There are countless environmental factors that are likely actually causing the gravel to deplete/compact. You will need more information to properly model these environmental factors - not just the distance along this road (which likely doesn’t provide much of any real predictive ability)
- You might be able to identify areas of high impact where extra shoring or supports might be needed. I also think it might be interesting to see the area effect looks like for gravel - i.e. if one section is heavily depleted, does that indicate anything about the surrounding sections?

Sound like an interesting dataset, especially if you can add some additional details to it.
- Your data essentially looks like a time series. You should be able to use any of the time series methodologies. 

There should be several causes of gravel depletion. Search for those that manifest themselves over 100s of meters. Anything below that, you cannot see in the dataset you have.
- There’s lots of software out there that does this kind of thing. Not specifically, because it’s not really that valuable to engineers, but combine two or three existing modelling programs and an engineer would solve this practically. 

Google geotechnical modelling software. Bentley Systems or Autodesk are probably an anchor point. ArcGIS & Plaxis or Leapfrog are the sort of thing to support. Geotechnical have this covered, one way or another. If they haven’t specifically adapted a program for it then it’s due to lack of demand. 

Also, by gravel, do you mean metalled road surface? Gravel/stoned roads are not that long. If so, ground faults would best be modelled by a measle diagram of potholes/repairs. Takes minutes to do.
- There are lots of factors which  contribute to aggregate loss including: traffic volume and composition ( I.e % of light and heavy vehicles) , gradient, curvature, travel speed. Also composition of the aggregate (types of rock and particle size distribution which influence the density at which it was compacted) , maintenance methods (e.g grading, rolling, application of water to aid compaction), typical moisture content (influenced by climate, topography, drainage channels and shape of the road surface) Unsealed road maintenance is generally considered “more of an art than a science” as there are so many variables. To analyse it, start by picking the factors which you think are likely to have an influence and analyse only sections of the 50km which have low variability in the other factors.
