URL: https://www.linkedin.com/posts/maryammiradi_machinelearning-artificialintelligence-activity-7183047297641918464-yVpX
Date: 2025-10-08
Author: Unknown

è·³åˆ°ä¸»è¦å†…å®¹
é¢†è‹±
çƒ­é—¨å†…å®¹
ä¼šå‘˜
é¢†è‹±å­¦ä¹ 
èŒä½
æ¸¸æˆ
ä¸‹è½½ APP
é©¬ä¸ŠåŠ å…¥
ç™»å½•
Maryam Miradi, PhDçš„åŠ¨æ€
Maryam Miradi, PhD

VP & Chief AI Scientist | 20+ Years in AI | AI Agents Training (LLM + Vision) | Data Science Training (ML + DL) | AI Newsletter (32k+ members)

1 å¹´  å·²ç¼–è¾‘

ğğ¯ğğ«ğœğ¨ğ¦ğ¢ğ§ğ  ğŒğ¨ğğğ¥ ğ”ğ§ğœğğ«ğ­ğšğ¢ğ§ğ­ğ² ğ¢ğ§ ğƒğğğ© ğ‹ğğšğ«ğ§ğ¢ğ§ğ : ğŸğŸ ğ“ğ¨ğ© ğğ²ğ­ğ¡ğ¨ğ§ ğ‹ğ¢ğ›ğ«ğšğ«ğ¢ğğ¬ ğšğ§ğ ğ’ğ¨ğ¥ğ®ğ­ğ¢ğ¨ğ§ğ¬

Deep learning has revolutionized the field of AI but with one major challenge: Model uncertainty.

ğ•„ğ• ğ••ğ•–ğ• ğ•Œğ•Ÿğ•”ğ•–ğ•£ğ•¥ğ•’ğ•šğ•Ÿğ•¥ğ•ª

Model's prediction probability is often used as a measure of uncertainty in the context of classification and this is not always correct because the model's predicted probabilities can be overly confident even when the true probabilities are well-known.

â„ğ•–ğ•’ğ•¤ğ• ğ•Ÿ ğ•’ğ•Ÿğ•• ğ•€ğ•ğ•¡ğ•’ğ•”ğ•¥

This can occur due to lack of data, noise, or the presence of conflicting information and leads to incorrect predictions.

ğ•‹ğ•ªğ•¡ğ•–ğ•¤ ğ• ğ•— ğ•„ğ• ğ••ğ•–ğ• ğ•Œğ•Ÿğ•”ğ•–ğ•£ğ•¥ğ•’ğ•šğ•Ÿğ•¥ğ•ª

âŠ Aleatoric uncertainty: due to inherent randomness in the data

â‹ Epistemic uncertainty: due to the lack of knowledge or information about the model

âŒ Model discrepancy: when the model's predictions are inconsistent with reality, which is a form of systematic error.

ğ•Šğ• ğ•ğ•¦ğ•¥ğ•šğ• ğ•Ÿğ•¤ ğ•¥ğ•  ğ•„ğ• ğ••ğ•–ğ• ğ•Œğ•Ÿğ•”ğ•–ğ•£ğ•¥ğ•’ğ•šğ•Ÿğ•¥ğ•ª

OÍ¡Íœ ğ‚ğšğ¥ğ¢ğ›ğ«ğšğ­ğ¢ğ¨ğ§: adjusts the predicted probabilities. common techniques: Platt scaling and isotonic regression.

OÍ¡Íœ ğ‚ğ¨ğ§ğŸğ¨ğ«ğ¦ğšğ¥ ğˆğ§ğŸğğ«ğğ§ğœğ: Constructs prediction intervals to quantify and communicate uncertainty in individual predictions

OÍ¡Íœ ğğšğ²ğğ¬ğ¢ğšğ§ ğ§ğğ®ğ«ğšğ¥ ğ§ğğ­ğ°ğ¨ğ«ğ¤ğ¬: use probability distributions to model uncertainty in the weights of the neural network.

OÍ¡Íœ ğƒğ«ğ¨ğ©ğ¨ğ®ğ­ ğ«ğğ ğ®ğ¥ğšğ«ğ¢ğ³ğšğ­ğ¢ğ¨ğ§: randomly drops out some neurons during training, which reduces overfitting and generalize better.

OÍ¡Íœ ğŒğ¨ğ§ğ­ğ ğ‚ğšğ«ğ¥ğ¨ ğğ«ğ¨ğ©ğ¨ğ®ğ­: uses dropout at inference time to obtain multiple predictions to estimate uncertainty.

OÍ¡Íœ ğƒğğğ© ğğ§ğ¬ğğ¦ğ›ğ¥ğğ¬: similar to ensemble models, with different initializations and architectures to further reduce uncertainty.

ğğ²ğ­ğ¡ğ¨ğ§ ğ‹ğ¢ğ›ğ«ğšğ«ğ¢ğğ¬:

ğŸ“š MAPIE 
Quantifying uncertainties and controlling the risks

ğŸ“šTensorFlow Probabilit