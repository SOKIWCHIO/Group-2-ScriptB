URL: https://www.linkedin.com/posts/belagiannis_iccvw2025-fau-deeplearning-activity-7362699687193120790-yQ7G
Date: 2025-10-08
Author: Unknown

è·³åˆ°ä¸»è¦å†…å®¹
é¢†è‹±
çƒ­é—¨å†…å®¹
ä¼šå‘˜
é¢†è‹±å­¦ä¹ 
èŒä½
æ¸¸æˆ
ä¸‹è½½ APP
é©¬ä¸ŠåŠ å…¥
ç™»å½•
Vasileios Belagiannisçš„åŠ¨æ€
Vasileios Belagiannis

Machine learning, Deep Learning and Computer Vision @ FAU

1 ä¸ªæœˆ

Teaching neural networks to say "I don't know". We have designed an uncertainty-aware likelihood ratio estimation method to detect unknown object categories at the pixel level. You should meet Marc HÃ¶lle in Honolulu in a few weeks to discuss the paper!

Made in FAU Erlangen-NÃ¼rnberg.

#ICCVW2025 #FAU #DeepLearning #AutomatedDriving #NeuralNetworks

Marc HÃ¶lle

Teaching machines to know what they donâ€™t know.

1 ä¸ªæœˆ

ğŸš— Teaching AI to Say â€œI Donâ€™t Knowâ€ and Why That Matters for Autonomous Driving ğŸ›‘

In real-world autonomous driving, perception systems donâ€™t just need to be accurate, they need to know when they donâ€™t know. Standard semantic segmentation models often misclassify unknown objects with alarming confidence, creating serious safety risks.

In our latest research, we introduce uncertainty-aware likelihood ratio estimation, a method that can reliably detect unknown objects at the pixel level, even in complex, cluttered driving scenes, where â€œI donâ€™t knowâ€ can be life-saving.

ğŸ” Whatâ€™s new?
 Instead of relying on single-point predictions, our approach leverages evidential deep learning to explicitly model uncertainty. This enables it to:
 â€¢ Reduce confusion between rare known objects and truly unknown ones;
 â€¢ Increase robustness to distributional shifts;
 â€¢ Leverage synthetic outlier exposure more effectively.

â­ Key results across five benchmark datasets:
 â€¢ Lowest average false detection rate: 2.5% (state-of-the-art);
 â€¢ High average precision: 90.91%;
 â€¢ Negligible computational overhead;
 â€¢ No drop in in-distribution segmentation accuracy.

ğŸ’¡ Why is this important?
Beyond these immediate results, our work lays the foundation for a general framework for statistical hypothesis testing with likelihood ratios under distributional uncertainty, a promising path toward safer and more trustworthy AI systems.

A 