Source: Reddit/MachineLearning
URL: https://reddit.com/r/MachineLearning/comments/10t4cxu/r_whats_your_suggestion_for_offline_rl/
Title: [R] What’s your suggestion for offline RL?

Content:
Hi guys! I read a lot of offline RL papers in last Fall semester and choose it as my course project. Offline RL seems to be a very hot topic in recent years, I believe that the major challenge for offline RL are (i) distribution shift and (ii) overestimation. The second challenge is caused by (i), because the learners/agents will never allow to interact with the true environment and they will too optimistic for unseen state-actions. Hence, there are many papers to address such challenges, e.g., CQL and MOPO.

However can these methods handle misleading datasets? Consider the following example. Suppose we have only one state (MAB) and two arms. The reward of the first arm will return 2/3 with probability 1 and the reward model of second arm is Bernoulli distribution with p=1/2. Clearly, choosing the first arm is the best choice.

Now, for the dataset, unfortunately, all samples on the second arm received reward 1. Because the agent only can access this misleading dataset, if we use Bayesian methods, then the posterior will give a high score for the second arm. If we use Lower Confidence Bound, we need to count the occurrence of each arm. Then, this is very hard to extend this method to MDPs with arbitrary large state and action space. So, does anyone know a function can capture this uncertainty (caused by the dataset) or can any methods to tell the learner that you’re in a very misleading situation?

Comments:
- I think you can generally use off policy techniques here, eg importance sampling.
- Thanks for answering. Suppose we know behavioural policy, pi_b(a). Let w(a) be the density ratio, w(a):=pi(a)/pi_b(a). Then, we add a penalty term, like f-divergence, D_f(pi(a)/pi_b(a)) = D_f(w(a)). There are algorithms, e.g., PRO-RL, designed for learning conservative policy based on importance sampling. My question, more specifically, how to measure the uncertainty caused by the small number of data points without counting, or is there any uncertainty function can capture counting information implicitly?
