URL: https://www.linkedin.com/posts/maxim-ziatdinov-651aab250_neurobayes-0012-is-out-now-featuring-activity-7301294788245368832-g8YJ
Date: 2025-10-08
Author: Unknown

跳到主要内容
领英
热门内容
会员
领英学习
职位
游戏
下载 APP
马上加入
登录
Maxim Ziatdinov的动态
Maxim Ziatdinov

Building AI tools for experimental materials discovery

7 个月  已编辑

🚀 NeuroBayes-0.0.12 is out! Now featuring Partially Bayesian Transformers and neuron-level control over model stochasticity.

Key Additions:
⚡ Partially Bayesian Transformers: Transformer neural networks are at the heart of modern AI systems and are increasingly used in physical sciences. However, robust uncertainty quantification with Transformers remains challenging. While replacing all weights with probabilistic distributions and using advanced sampling techniques works for smaller networks, this approach is computationally prohibitive for Transformers. Our new partially Bayesian Transformer implementation allows you to selectively make specific modules (embedding, attention, etc.) probabilistic while keeping others deterministic, significantly reducing computational costs while still delivering reliable uncertainty quantification.

⚡ Fine-grained Stochasticity Control: Even with only some layers probabilistic, training deep learning models can be resource-intensive. You can now specify exactly which weights in particular layers should be stochastic, providing a finer control over the computational cost vs. uncertainty trade-off.

📚 Probabilistic SMILES-Transformer example: https://lnkd.in/gCZVKUYT
⭐ GitHub repo: https://lnkd.in/e-t3vz9Y (please add a star!)

Next stop: Partially Bayesian Graph Nets

41
赞
评论
分享

要查看或添加评论，请登录

6,357 位关注者

197 则动态
查看档案  关注
浏览内容分类
Career
Productivity
Finance
Soft Skills & Emotional Intelligence
Project Management
Education
展开 
领英
© 2025
关于
无障碍模式
用户协议
隐私政策
《加利福尼亚隐私选择》
Cookie 政策
版权政策
品牌政策
访客设置
社区准则
语言
登录查看更多内容

创建帐号或登录后继续搜索

登录帐号: 思齐
S*****@163.com

或

没有领英帐号？立即加入

点击“继续加入或登录”，即表示您同意遵守领英的《用户协议》、《隐私政策》及《Cookie 政策》。