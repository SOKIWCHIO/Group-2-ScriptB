URL: https://www.linkedin.com/posts/krider2010_gpt-5-prompting-guide-openai-cookbook-activity-7359622731971059712-_4L-
Date: 2025-10-08
Author: Unknown

è·³åˆ°ä¸»è¦å†…å®¹
é¢†è‹±
çƒ­é—¨å†…å®¹
ä¼šå‘˜
é¢†è‹±å­¦ä¹ 
èŒä½
æ¸¸æˆ
ä¸‹è½½ APP
é©¬ä¸ŠåŠ å…¥
ç™»å½•
Dr Claire Knightçš„åŠ¨æ€
Dr Claire Knight
2 ä¸ªæœˆ

You can't treat LLM Models like APIs. While it's tempting, and you do make calls to them via an API, they don't provide you with a contract beyond the communication layer. What happens is that you call the API, and you get back 200 and vibes! (Or sometimes a 429 because tokens and $$$$$ ğŸ¤ª)

Engineers quite rightly love contracts. Interfaces, schemas, return types, status codes. Stuff you can rely on. Build around. Deterministic things. LLMs? None of that, beyond the 200 OK response. The same prompt might give you a solid result at 2pm and nonsense at 2:03pm. Or maybe it hallucinated a button label for a feature you don't have. Or answered in German because it saw a stray â€œGuten Tagâ€ in the context window.

Even worse, things can change underneath you. I think many people are finding that out the hard way today. Yesterday OpenAI released their latest model GPT-5. You probably didn't change your code. You likely didn't even redeploy, unless you were smart enough to pin to a model. But behaviours could be shifting: a summarisation endpoint is now â€œmore conciseâ€ (aka drops key details), your chatbot is faster but more literal, or your extraction prompt starts returning subtly different formats. That carefully crafted prompt is no longer the best one. I mean even the model creators posted about how to get the best out of the new model with a change in prompting (https://lnkd.in/eWWbAFN2). And I'm seeing a lot of "going back to 4 or claude or ..." - and that's in the tech savvy space.

Your users will think you broke it. You may think nothing has changed. But the harsh reality is that the ground moved under both sides. Users are not going to care. It's just a dependency in your system so in their eyes it's your fault. Welcome to the world of probabilistic systems. Where you canâ€™t reliably reproduce so canâ€™t debug in the ways you are used to. And canâ€™t even say with certainty what went w