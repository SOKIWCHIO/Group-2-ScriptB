URL: https://www.linkedin.com/posts/maryammiradi_machinelearning-artificialintelligence-activity-7090269617817812998-c5qs?trk=public_profile_like_view
Date: 2025-10-08
Author: Unknown

è·³åˆ°ä¸»è¦å†…å®¹
é¢†è‹±
çƒ­é—¨å†…å®¹
ä¼šå‘˜
é¢†è‹±å­¦ä¹ 
èŒä½
æ¸¸æˆ
ä¸‹è½½ APP
é©¬ä¸ŠåŠ å…¥
ç™»å½•
Maryam Miradi, PhDçš„åŠ¨æ€
Maryam Miradi, PhD

VP & Chief AI Scientist | 20+ Years in AI | AI Agents Training (LLM + Vision) | Data Science Training (ML + DL) | AI Newsletter (32k+ members)

2 å¹´  å·²ç¼–è¾‘

ğğ¯ğğ«ğœğ¨ğ¦ğ¢ğ§ğ  ğŒğ¨ğğğ¥ ğ”ğ§ğœğğ«ğ­ğšğ¢ğ§ğ­ğ² ğ¢ğ§ ğƒğğğ© ğ‹ğğšğ«ğ§ğ¢ğ§ğ : ğŸğŸ ğ“ğ¨ğ© ğğ²ğ­ğ¡ğ¨ğ§ ğ‹ğ¢ğ›ğ«ğšğ«ğ¢ğğ¬ ğšğ§ğ ğ’ğ¨ğ¥ğ®ğ­ğ¢ğ¨ğ§ğ¬

Deep learning has revolutionized the field of AI but with one major challenge: Model uncertainty.

ğ•„ğ• ğ••ğ•–ğ• ğ•Œğ•Ÿğ•”ğ•–ğ•£ğ•¥ğ•’ğ•šğ•Ÿğ•¥ğ•ª

Model's prediction probability is often used as a measure of uncertainty in the context of classification and this is not always correct because the model's predicted probabilities can be overly confident even when the true probabilities are well-known.

ğ•‹ğ•™ğ•– â„ğ•–ğ•’ğ•¤ğ• ğ•Ÿ ğ•’ğ•Ÿğ•• ğ•‹ğ•™ğ•– ğ•€ğ•ğ•¡ğ•’ğ•”ğ•¥

This can occur due to lack of data, noise, or the presence of conflicting information and leads to incorrect predictions.

ğ•‹ğ•ªğ•¡ğ•–ğ•¤ ğ• ğ•— ğ•„ğ• ğ••ğ•–ğ• ğ•Œğ•Ÿğ•”ğ•–ğ•£ğ•¥ğ•’ğ•šğ•Ÿğ•¥ğ•ª

âŠ Aleatoric uncertainty: due to inherent randomness in the data

â‹ Epistemic uncertainty: due to the lack of knowledge or information about the model

âŒ Model discrepancy: when the model's predictions are inconsistent with reality, which is a form of systematic error.

ğ•Šğ• ğ•ğ•¦ğ•¥ğ•šğ• ğ•Ÿğ•¤ ğ•¥ğ•  ğ•„ğ• ğ••ğ•–ğ• ğ•Œğ•Ÿğ•”ğ•–ğ•£ğ•¥ğ•’ğ•šğ•Ÿğ•¥ğ•ª

OÍ¡Íœ ğ‚ğšğ¥ğ¢ğ›ğ«ğšğ­ğ¢ğ¨ğ§: adjusts the predicted probabilities to better align with the true class proportions. Two common calibration techniques are Platt scaling and isotonic regression.

OÍ¡Íœ ğğšğ²ğğ¬ğ¢ğšğ§ ğ§ğğ®ğ«ğšğ¥ ğ§ğğ­ğ°ğ¨ğ«ğ¤ğ¬: use probability distributions to model uncertainty in the weights of the neural network.

OÍ¡Íœ ğƒğ«ğ¨ğ©ğ¨ğ®ğ­ ğ«ğğ ğ®ğ¥ğšğ«ğ¢ğ³ğšğ­ğ¢ğ¨ğ§: randomly drops out some neurons during training, which reduces overfitting and helps the model to generalize better.

OÍ¡Íœ ğ„ğ§ğ¬ğğ¦ğ›ğ¥ğ ğ¦ğ¨ğğğ¥ğ¬: combine multiple models to improve accuracy and reduce uncertainty. 

OÍ¡Íœ ğŒğ¨ğ§ğ­ğ ğ‚ğšğ«ğ¥ğ¨ ğğ«ğ¨ğ©ğ¨ğ®ğ­: uses dropout at inference time to obtain multiple predictions to estimate uncertainty.

OÍ¡Íœ ğƒğğğ© ğğ§ğ¬ğğ¦ğ›ğ¥ğğ¬: are similar to ensemble models, but they use different initializations and architectures to further reduce uncertainty.

ğ“ğ¡ğğ¬ğ ğšğ«ğ ğ­ğ¡ğ ğğ²ğ­ğ¡ğ¨ğ§ ğ‹ğ¢ğ›ğ«ğšğ«ğ¢ğğ¬