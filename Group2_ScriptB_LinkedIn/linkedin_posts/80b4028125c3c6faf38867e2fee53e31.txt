URL: https://www.linkedin.com/posts/christoph-molnar_picking-an-ml-model-class-because-of-interpretability-activity-7108042090432880640-9UvD
Date: 2025-10-08
Author: Unknown

è·³åˆ°ä¸»è¦å†…å®¹
é¢†è‹±
çƒ­é—¨å†…å®¹
ä¼šå‘˜
é¢†è‹±å­¦ä¹ 
èŒä½
æ¸¸æˆ
ä¸‹è½½ APP
é©¬ä¸ŠåŠ å…¥
ç™»å½•
Christoph Molnarçš„åŠ¨æ€
Christoph Molnar

Author of Interpretable Machine Learning, Modeling Mindsets, and more | christophmolnar.com

2 å¹´

Picking an ML model class because of interpretability or built-in "conveniences" such as uncertainty quantification is a sure way to lose out on performance.

But thanks to model-agnostic tools, you can have your cake and eat it too. Or at least have some bites. 

If you aren't attached to a certain model class, but pick the "winner" from model selection, then you have to be agnostic as to which model comes out.

Your only option for extras such as UQ and interpretability is model-agnostic tools.

Here's a list to save for later:


ðŸŽ² Uncertainty quantification

Use conformal prediction to quantify the uncertainty of any model. CP turns "weak" uncertainty scores into rigorous prediction intervals.

For example:

class probabilities -> classification sets
quantile regression -> conformalized quantile regression

https://buff.ly/3PzaUwy 


ðŸ’¡ Interpretation

There are so many model-agnostic interpretation methods, you could write a book ðŸ˜‰. A selection:

â€¢ SHAP  for explaining individual predictions
â€¢ Permutation feature importance
â€¢ Partial dependence plots for feature effects
...


https://buff.ly/45Lmvyd 


ðŸŽ¯ Analysis of variance for ML

Functions can be decomposed into lower dimensional components. Decomposition is related to interpretability but offers more advantages: An attribution of the target's variance to individual features (like ANOVA in stats)

https://buff.ly/3LiSvBM 


â†£ Causality

Orthogonal/double machine learning brings supervised learning to causal effect estimation. It's based on training two ML models (one for treatment, one for control).


ðŸ“‰ Design your loss/evaluation metric

Some tasks seemingly have a limited range of specialized models that can solve them. Like for quantile regression. But you can turn these into model-agnostic tasks if you translate the task into a l