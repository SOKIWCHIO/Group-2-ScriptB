URL: https://www.linkedin.com/posts/laurencehook_deceitful-llms-are-getting-me-down-anthropic-activity-7362658333385785344-elw6
Date: 2025-10-08
Author: Unknown

è·³åˆ°ä¸»è¦å†…å®¹
é¢†è‹±
çƒ­é—¨å†…å®¹
ä¼šå‘˜
é¢†è‹±å­¦ä¹ 
èŒä½
æ¸¸æˆ
ä¸‹è½½ APP
é©¬ä¸ŠåŠ å…¥
ç™»å½•
Laurence Hookçš„åŠ¨æ€
Laurence Hook

Co-Founder @ Fintech Startup. Ex Revolut HSBC JPMC

1 ä¸ªæœˆ  å·²ç¼–è¾‘

Deceitful LLMs are getting me downâ€¦

Anthropic, your new models canâ€™t help themselves. The urge to â€œcompleteâ€ and declare success beats any instruction to tell the truth.

Iâ€™ve tried hooks, output styles, even a CLAUDE.md full of rules: â€œdonâ€™t say tests passed if they didnâ€™t.â€ Stillâ€”Claude smiles, says all green, and suggests committing junk.

The real problem in AI isnâ€™t hallucinationâ€”itâ€™s lying. And I worry how much code is shipping with hidden shortcuts like â€œjust return mock data for now.â€ ğŸ˜“

The silver lining? The hype about engineers being replaced is mostly consultant fiction.


61
19 æ¡è¯„è®º
èµ
è¯„è®º
åˆ†äº«
Charles Anthony Proctor-Browne

Full Stack Engineering Assoc Manager @ Accenture

1 ä¸ªæœˆ

I understand the sentiment - but It's not lieing, LLM models don't have the concept of truth or lies.

They're very sophisticated pattern matching, they try to predict the "what comes next". What it's kind of doing is saying "Statistically, based on the training data I was trained on, this is the most likely response"

Even if you give it a list of instructions. It's still taking those instructions, and saying "based on these rules and what I was trained on, this is what I should do". The more specific the less statistical variance you might encounter but you're still playing that statistical game

èµ
å›å¤
Oliver Graham

Software Architect & Engineer âœ¦ AI Specialist âœ¦ Helping millions achieve better health

1 ä¸ªæœˆ

Still hoping for deterministic outputs from a probabilistic model?

èµ
å›å¤
2 æ¬¡å›åº”
Ryan Bright

Engineering at Moonrise Labs

1 ä¸ªæœˆ

The best is when it knows some tests are failing, gives up, and then says "these are failing, but it's fine".

Anyone generating tested code without detailed review is 100% shipping mocks, skipped tests, tests that make tautological assertions, and lots of other wild stuff the LLMs do to satisfy their reward func