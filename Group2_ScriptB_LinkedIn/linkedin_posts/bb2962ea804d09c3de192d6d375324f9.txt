URL: https://www.linkedin.com/posts/aayush-sugandh-785181190_things-that-generally-might-not-have-been-activity-7339356768352837633-YoIv
Date: 2025-10-08
Author: Unknown

跳到主要内容
领英
热门内容
会员
领英学习
职位
游戏
下载 APP
马上加入
登录
Aayush Sugandh的动态
Aayush Sugandh

IIT Kgp | Synopsys | Jadavpur University

3 个月  已编辑

Things that generally might not have been heard by an ML novice: 

Epistemic vs Aleatoric Uncertainity - One signifying lack of knowledge of the input-output mapping, and one signifying inherent stocasticity in the mappings.

Population Risk(the loss we actually want to compute), but end up computing empirical risk. We thus have the concept of “Generalization Gap”.

The well known probabilistic principal component analysis is a special case of factor analysis,(where the linear model which is framed as observing high dimension output sample from a normal distribution with mean dependent on latent and covariance matrix) has covariance as identity. 

Why we take “log” in TF-IDF formulation. Hint: How the log function grows. 

Handling missing data : Missing completely at random(MCAR), Missing at Random(MAR) and not missing at random(NMAR). If it’s NMAR we cannot ignore missingness, and certain imputation schemes that we take to remedy.

11
赞
评论
分享

要查看或添加评论，请登录

9,323 位关注者

252 则动态
查看档案  关注
探索相关领域
Tips for Machine Learning Success
How to Optimize Machine Learning Performance
Challenges Faced by ML Engineers
Common Mistakes in Financial Modeling
Common Mistakes That Hinder AI Adoption
Challenges in Training Neural Models
展开 
浏览内容分类
Career
Productivity
Finance
Soft Skills & Emotional Intelligence
Project Management
Education
展开 
领英
© 2025
关于
无障碍模式
用户协议
隐私政策
《加利福尼亚隐私选择》
Cookie 政策
版权政策
品牌政策
访客设置
社区准则
语言
登录查看更多内容

创建帐号或登录后继续搜索

登录帐号: 思齐
S*****@163.com

或

没有领英帐号？立即加入

点击“继续加入或登录”，即表示您同意遵守领英的《用户协议》、《隐私政策》及《Cookie 政策》。