URL: https://www.linkedin.com/posts/daniel-aronovich_data-science-mathematics-activity-7272901854248787968-tAL3
Date: 2025-10-08
Author: Unknown

è·³åˆ°ä¸»è¦å†…å®¹
é¢†è‹±
çƒ­é—¨å†…å®¹
ä¼šå‘˜
é¢†è‹±å­¦ä¹ 
èŒä½
æ¸¸æˆ
ä¸‹è½½ APP
é©¬ä¸ŠåŠ å…¥
ç™»å½•
Daniel A.çš„åŠ¨æ€
Daniel A.

Co-Founder and CTO at Dataflint | Apache Spark Copilot | Podcast Host | Passionate about Data, Math and Leadership

10 ä¸ªæœˆ

How to ğªğ®ğšğ§ğ­ğ¢ğŸğ² ğ®ğ§ğœğğ«ğ­ğšğ¢ğ§ğ­ğ² in machine learning?

In this episode of the ğƒğšğ­ğš ğ’ğœğ¢ğğ§ğœğ ğ“ğ‹ğƒğ‘, I review the paper: 

Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks[1] by Michael Kirchhof.

Which investigates whether current machine learning methods can effectively disentangle aleatoric and epistemic uncertainties, two critical types of uncertainty in AI systems.

ğ€ğ¥ğğšğ­ğ¨ğ«ğ¢ğœ ğ®ğ§ğœğğ«ğ­ğšğ¢ğ§ğ­ğ² corresponds to inherent variability or ambiguity in the data itself, similar to interpolation, as it deals with situations within the known data distribution that cannot be resolved regardless of additional data or model improvements.

ğ„ğ©ğ¢ğ¬ğ­ğğ¦ğ¢ğœ ğ®ğ§ğœğğ«ğ­ğšğ¢ğ§ğ­ğ², on the other hand, arises from gaps in the model's knowledge or exposure, akin to extrapolation, as it reflects uncertainty when encountering data outside the training distribution that can potentially be reduced with more data or better modeling.

The authors benchmarked 19 uncertainty quantification methods across 13 tasks, including out-of-distribution detection and predictive uncertainty calibration, using large-scale datasets like ImageNet and CIFAR-10.

Traditional mathematical decompositions, such as the Information-Theoretical formula, aim to separate these uncertainties but fail in practice, with aleatoric and epistemic components showing high correlations (rank correlations above 0.78).

This overlap suggests that these ğ¦ğğ­ğ¡ğ¨ğğ¬ ğšğ«ğ ğ§ğ¨ğ­ ğ­ğ«ğ®ğ¥ğ² ğğ¢ğ¬ğğ§ğ­ğšğ§ğ ğ¥ğ¢ğ§ğ  ğ®ğ§ğœğğ«ğ­ğšğ¢ğ§ğ­ğ¢ğğ¬ as expected, undermining their practical utility in applications like active learning and safety-critical systems.

The paper highlights that some methods, like the Mahalanobis distance, excel at specific tasks, such as detecting out-of-distribution samples, without being confounded by aleatoric uncertainty.

The findings emphasiz