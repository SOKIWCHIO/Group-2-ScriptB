import os
import shutil
import pandas as pd
import numpy as np
from pathlib import Path
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
# import seaborn as sns
from typing import List, Dict
import json

# ============================================================================
# é…ç½®
# ============================================================================
INPUT_FOLDERS = [
    "linkedin_posts",
    "Reddit_posts"
]
OUTPUT_FOLDER = "filtered_posts"
STATS_FOLDER = "filter_stats"

# è¯­ä¹‰è¿‡æ»¤å‚æ•°
MODEL_NAME = 'all-MiniLM-L6-v2'
THRESHOLD = 30.0  # å¯è°ƒæ•´: 20(å®½æ¾) - 30(å¹³è¡¡) - 40(ä¸¥æ ¼)
BATCH_SIZE = 32

# ä¸ç¡®å®šæ€§ä¸»é¢˜æŸ¥è¯¢
UNCERTAINTY_QUERIES = [
    "uncertainty estimation in deep learning models",
    "Bayesian neural networks for uncertainty quantification", 
    "epistemic and aleatoric uncertainty in machine learning",
    "confidence calibration in neural networks",
    "probabilistic predictions and uncertainty measures",
    "out-of-distribution detection using uncertainty",
    "predictive uncertainty in AI systems",
    "uncertainty-aware deep learning methods",
    "Monte Carlo dropout for uncertainty estimation",
    "ensemble methods for uncertainty quantification"
]

# ============================================================================
# æ¸…ç©ºæ—§ç»“æœ â­ æ–°å¢
# ============================================================================
def clean_previous_results():
    """æ¸…ç©ºä¸Šæ¬¡è¿è¡Œçš„ç»“æœ"""
    folders_to_clean = [OUTPUT_FOLDER, STATS_FOLDER]
    
    print(f"\nğŸ§¹ Cleaning previous results...")
    for folder in folders_to_clean:
        if os.path.exists(folder):
            try:
                shutil.rmtree(folder)
                print(f"   âœ“ Removed old folder: {folder}/")
            except Exception as e:
                print(f"   âš ï¸  Could not remove {folder}/: {e}")
        
        # é‡æ–°åˆ›å»ºç©ºæ–‡ä»¶å¤¹
        os.makedirs(folder, exist_ok=True)
        print(f"   âœ“ Created clean folder: {folder}/")
    print()

# ============================================================================
# è¯­ä¹‰è¿‡æ»¤å™¨
# ============================================================================
class UncertaintySemanticFilter:
    """ä¸ç¡®å®šæ€§ä¸»é¢˜çš„è¯­ä¹‰è¿‡æ»¤å™¨"""
    
    def __init__(self, queries: List[str], model_name: str = MODEL_NAME):
        print(f"ğŸ”§ Initializing Semantic Filter...")
        print(f"   Model: {model_name}")
        self.model = SentenceTransformer(model_name)
        self.queries = queries
        self._query_embeddings = None
        
    def _encode_queries(self):
        """ç¼–ç æŸ¥è¯¢ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰"""
        if self._query_embeddings is None:
            print(f"ğŸ“ Encoding {len(self.queries)} uncertainty queries...")
            self._query_embeddings = self.model.encode(
                self.queries,
                show_progress_bar=False,
                convert_to_numpy=True
            )
            print("   âœ“ Queries encoded")
        return self._query_embeddings
    
    def compute_scores(self, texts: List[str], batch_size: int = BATCH_SIZE):
        """è®¡ç®—æ–‡æœ¬ç›¸å…³æ€§åˆ†æ•°"""
        print(f"\nğŸ” Computing semantic scores for {len(texts)} texts...")
        
        # ç¼–ç æŸ¥è¯¢
        query_embeddings = self._encode_queries()
        
        # ç¼–ç æ–‡æ¡£
        print("   Encoding documents...")
        doc_embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=True,
            convert_to_numpy=True
        )
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        print("   Computing similarities...")
        similarities = cosine_similarity(query_embeddings, doc_embeddings)
        
        # ä½¿ç”¨æœ€å¤§ç›¸ä¼¼åº¦ä½œä¸ºåˆ†æ•°
        max_similarity = similarities.max(axis=0)
        avg_similarity = similarities.mean(axis=0)
        
        # è½¬æ¢ä¸º 0-100 åˆ†æ•°
        scores = (max_similarity * 100).clip(0, 100)
        
        print(f"   âœ“ Score range: {scores.min():.2f} - {scores.max():.2f}")
        print(f"   âœ“ Mean score: {scores.mean():.2f}")
        
        return {
            'scores': scores,
            'max_similarity': max_similarity,
            'avg_similarity': avg_similarity
        }

# ============================================================================
# æ–‡æœ¬è¯»å–
# ============================================================================
def read_text_files(folders: List[str]) -> pd.DataFrame:
    """
    ä»å¤šä¸ªæ–‡ä»¶å¤¹è¯»å–æ–‡æœ¬æ–‡ä»¶
    
    è¿”å›: DataFrame with columns [filename, text, source]
    """
    print(f"\nğŸ“‚ Reading text files from {len(folders)} folders...")
    
    all_data = []
    for folder in folders:
        if not os.path.exists(folder):
            print(f"   âš ï¸  Folder not found: {folder}, skipping")
            continue
        
        folder_path = Path(folder)
        txt_files = list(folder_path.glob("*.txt"))
        print(f"   ğŸ“ {folder}: {len(txt_files)} files")
        
        for file_path in txt_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    all_data.append({
                        'filename': file_path.name,
                        'text': content,
                        'source': folder
                    })
            except Exception as e:
                print(f"      âŒ Error reading {file_path.name}: {e}")
    
    df = pd.DataFrame(all_data)
    print(f"\nâœ… Total texts loaded: {len(df)}")
    if len(df) > 0:
        print(f"   Sources: {df['source'].value_counts().to_dict()}")
    
    return df

# ============================================================================
# è¿‡æ»¤å‡½æ•°
# ============================================================================
def filter_texts(df: pd.DataFrame, threshold: float = THRESHOLD):
    """
    åŸºäºè¯­ä¹‰åˆ†æ•°è¿‡æ»¤æ–‡æœ¬
    """
    print(f"\n{'='*70}")
    print(f"SEMANTIC FILTERING")
    print(f"{'='*70}")
    print(f"Input texts: {len(df)}")
    print(f"Threshold: {threshold}")
    print(f"{'='*70}\n")
    
    # åˆå§‹åŒ–è¿‡æ»¤å™¨
    filter_model = UncertaintySemanticFilter(UNCERTAINTY_QUERIES)
    
    # è®¡ç®—åˆ†æ•°
    texts = df['text'].tolist()
    score_results = filter_model.compute_scores(texts)
    
    # æ·»åŠ åˆ†æ•°åˆ° DataFrame
    df['semantic_score'] = score_results['scores']
    df['max_similarity'] = score_results['max_similarity']
    df['avg_similarity'] = score_results['avg_similarity']
    
    # åº”ç”¨é˜ˆå€¼
    filtered_df = df[df['semantic_score'] >= threshold].copy()
    
    # ç»Ÿè®¡
    print(f"\n{'='*70}")
    print(f"FILTERING RESULTS")
    print(f"{'='*70}")
    print(f"Original:  {len(df):>6} texts")
    print(f"Kept:      {len(filtered_df):>6} texts ({len(filtered_df)/len(df)*100:>5.1f}%)")
    print(f"Removed:   {len(df)-len(filtered_df):>6} texts ({(len(df)-len(filtered_df))/len(df)*100:>5.1f}%)")
    print(f"{'='*70}\n")
    
    # æŒ‰æ¥æºç»Ÿè®¡
    if len(df) > 0:
        print("Filtering by source:")
        for source in df['source'].unique():
            source_total = len(df[df['source'] == source])
            source_kept = len(filtered_df[filtered_df['source'] == source])
            print(f"  {source}: {source_kept}/{source_total} ({source_kept/source_total*100:.1f}%)")
    
    return filtered_df, df

# ============================================================================
# ä¿å­˜ç»“æœ
# ============================================================================
def save_filtered_texts(filtered_df: pd.DataFrame, output_folder: str):
    """ä¿å­˜è¿‡æ»¤åçš„æ–‡æœ¬"""
    print(f"\nğŸ’¾ Saving filtered texts to {output_folder}/")
    
    # ä¿å­˜æ¯ä¸ªæ–‡æœ¬æ–‡ä»¶
    for idx, row in filtered_df.iterrows():
        output_path = os.path.join(output_folder, row['filename'])
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(row['text'])
    
    print(f"   âœ“ Saved {len(filtered_df)} files")

def save_statistics(filtered_df: pd.DataFrame, all_df: pd.DataFrame, stats_folder: str):
    """ä¿å­˜ç»Ÿè®¡ä¿¡æ¯å’Œå¯è§†åŒ–"""
    print(f"\nğŸ“Š Generating statistics and visualizations...")
    
    # 1. ä¿å­˜åˆ†æ•° CSV
    all_df[['filename', 'source', 'semantic_score', 'max_similarity', 'avg_similarity']].to_csv(
        os.path.join(stats_folder, 'all_scores.csv'),
        index=False,
        encoding='utf-8-sig'
    )
    
    filtered_df[['filename', 'source', 'semantic_score', 'max_similarity', 'avg_similarity']].to_csv(
        os.path.join(stats_folder, 'filtered_scores.csv'),
        index=False,
        encoding='utf-8-sig'
    )
    
    # 2. ä¿å­˜ JSON æ‘˜è¦
    summary = {
        'total_input': len(all_df),
        'total_filtered': len(filtered_df),
        'filter_rate': len(filtered_df) / len(all_df) * 100 if len(all_df) > 0 else 0,
        'threshold_used': THRESHOLD,
        'score_stats': {
            'all': {
                'mean': float(all_df['semantic_score'].mean()),
                'median': float(all_df['semantic_score'].median()),
                'min': float(all_df['semantic_score'].min()),
                'max': float(all_df['semantic_score'].max())
            },
            'filtered': {
                'mean': float(filtered_df['semantic_score'].mean()) if len(filtered_df) > 0 else 0,
                'median': float(filtered_df['semantic_score'].median()) if len(filtered_df) > 0 else 0,
                'min': float(filtered_df['semantic_score'].min()) if len(filtered_df) > 0 else 0,
                'max': float(filtered_df['semantic_score'].max()) if len(filtered_df) > 0 else 0
            }
        },
        'by_source': {}
    }
    
    for source in all_df['source'].unique():
        source_total = len(all_df[all_df['source'] == source])
        source_kept = len(filtered_df[filtered_df['source'] == source])
        summary['by_source'][source] = {
            'total': source_total,
            'kept': source_kept,
            'rate': source_kept / source_total * 100 if source_total > 0 else 0
        }
    
    with open(os.path.join(stats_folder, 'filter_summary.json'), 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    # 3. ç”Ÿæˆå¯è§†åŒ–
    generate_visualizations(all_df, filtered_df, stats_folder)
    
    print(f"   âœ“ Statistics saved to {stats_folder}/")

# ============================================================================
# å¯è§†åŒ–ï¼ˆä¸ä½¿ç”¨ seabornï¼‰â­ ä¿®æ”¹
# ============================================================================
def generate_visualizations(all_df: pd.DataFrame, filtered_df: pd.DataFrame, stats_folder: str):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆçº¯ matplotlibï¼‰"""
    
    # è®¾ç½®æ ·å¼
    plt.style.use('seaborn-v0_8-darkgrid')
    plt.rcParams['figure.facecolor'] = 'white'
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # 1. åˆ†æ•°åˆ†å¸ƒç›´æ–¹å›¾
    ax = axes[0, 0]
    ax.hist(all_df['semantic_score'], bins=50, alpha=0.6, color='gray', label='All', edgecolor='black')
    ax.hist(filtered_df['semantic_score'], bins=50, alpha=0.8, color='green', label='Kept', edgecolor='black')
    ax.axvline(THRESHOLD, color='red', linestyle='--', linewidth=2, label=f'Threshold={THRESHOLD}')
    ax.set_xlabel('Semantic Score', fontsize=12)
    ax.set_ylabel('Frequency', fontsize=12)
    ax.set_title('Score Distribution', fontsize=14, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 2. ç´¯ç§¯åˆ†å¸ƒ
    ax = axes[0, 1]
    sorted_scores = np.sort(all_df['semantic_score'])
    cumulative = np.arange(1, len(sorted_scores) + 1) / len(sorted_scores) * 100
    ax.plot(sorted_scores, cumulative, linewidth=2, color='steelblue')
    ax.axvline(THRESHOLD, color='red', linestyle='--', linewidth=2, label=f'Threshold={THRESHOLD}')
    ax.axhline(50, color='gray', linestyle=':', alpha=0.5)
    ax.set_xlabel('Semantic Score', fontsize=12)
    ax.set_ylabel('Cumulative %', fontsize=12)
    ax.set_title('Cumulative Distribution', fontsize=14, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 3. æŒ‰æ¥æºç»Ÿè®¡
    ax = axes[0, 2]
    source_stats = []
    for source in all_df['source'].unique():
        total = len(all_df[all_df['source'] == source])
        kept = len(filtered_df[filtered_df['source'] == source])
        source_stats.append({'Source': source, 'Kept': kept, 'Removed': total - kept})
    
    if len(source_stats) > 0:
        stats_df = pd.DataFrame(source_stats)
        x = np.arange(len(stats_df))
        width = 0.6
        
        ax.bar(x, stats_df['Kept'], width, label='Kept', color='lightgreen')
        ax.bar(x, stats_df['Removed'], width, bottom=stats_df['Kept'], label='Removed', color='lightcoral')
        
        ax.set_ylabel('Count', fontsize=12)
        ax.set_title('Filtering by Source', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(stats_df['Source'], rotation=45, ha='right')
        ax.legend()
    
    # 4. ç®±çº¿å›¾å¯¹æ¯”
    ax = axes[1, 0]
    kept_scores = filtered_df['semantic_score'].values
    removed_scores = all_df[all_df['semantic_score'] < THRESHOLD]['semantic_score'].values
    
    bp = ax.boxplot([kept_scores, removed_scores], labels=['Kept', 'Removed'], patch_artist=True)
    bp['boxes'][0].set_facecolor('lightgreen')
    bp['boxes'][1].set_facecolor('lightcoral')
    ax.set_ylabel('Semantic Score', fontsize=12)
    ax.set_title('Score Comparison', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3, axis='y')
    
    # 5. åˆ†æ•° vs æ¥æºï¼ˆåˆ†ç»„æ¡å½¢å›¾ï¼‰
    ax = axes[1, 1]
    sources = all_df['source'].unique()
    kept_means = []
    removed_means = []
    
    for source in sources:
        source_df = all_df[all_df['source'] == source]
        kept_mask = source_df['semantic_score'] >= THRESHOLD
        
        kept_mean = source_df[kept_mask]['semantic_score'].mean() if kept_mask.sum() > 0 else 0
        removed_mean = source_df[~kept_mask]['semantic_score'].mean() if (~kept_mask).sum() > 0 else 0
        
        kept_means.append(kept_mean)
        removed_means.append(removed_mean)
    
    x = np.arange(len(sources))
    width = 0.35
    
    ax.bar(x - width/2, kept_means, width, label='Kept', color='lightgreen')
    ax.bar(x + width/2, removed_means, width, label='Removed', color='lightcoral')
    
    ax.set_ylabel('Mean Semantic Score', fontsize=12)
    ax.set_xlabel('Source', fontsize=12)
    ax.set_title('Average Score by Source & Status', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(sources, rotation=45, ha='right')
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    
    # 6. ç»Ÿè®¡è¡¨æ ¼
    ax = axes[1, 2]
    ax.axis('off')
    
    table_data = [
        ['Metric', 'Value'],
        ['', ''],
        ['Total Input', f"{len(all_df)}"],
        ['Kept', f"{len(filtered_df)} ({len(filtered_df)/len(all_df)*100:.1f}%)"],
        ['Removed', f"{len(all_df)-len(filtered_df)} ({(len(all_df)-len(filtered_df))/len(all_df)*100:.1f}%)"],
        ['', ''],
        ['Score (Kept)', ''],
        ['  Mean', f"{filtered_df['semantic_score'].mean():.2f}" if len(filtered_df) > 0 else "N/A"],
        ['  Median', f"{filtered_df['semantic_score'].median():.2f}" if len(filtered_df) > 0 else "N/A"],
        ['  Min', f"{filtered_df['semantic_score'].min():.2f}" if len(filtered_df) > 0 else "N/A"],
        ['  Max', f"{filtered_df['semantic_score'].max():.2f}" if len(filtered_df) > 0 else "N/A"],
    ]
    
    table = ax.table(cellText=table_data, cellLoc='left', loc='center', colWidths=[0.5, 0.5])
    table.auto_set_font_size(False)
    table.set_fontsize(11)
    table.scale(1, 2.5)
    
    for i in range(2):
        table[(0, i)].set_facecolor('#40466e')
        table[(0, i)].set_text_props(weight='bold', color='white')
    
    plt.tight_layout()
    plt.savefig(os.path.join(stats_folder, 'filtering_analysis.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"   âœ“ Visualization saved: filtering_analysis.png")

# ============================================================================
# æ˜¾ç¤ºæ ·æœ¬
# ============================================================================
def print_sample_texts(filtered_df: pd.DataFrame, n_samples: int = 5):
    """æ‰“å°é«˜åˆ†æ ·æœ¬"""
    if len(filtered_df) == 0:
        print("\nâš ï¸  No texts passed the filter!")
        return
    
    print(f"\n{'='*70}")
    print(f"TOP {min(n_samples, len(filtered_df))} MOST RELEVANT TEXTS")
    print(f"{'='*70}\n")
    
    top_samples = filtered_df.nlargest(min(n_samples, len(filtered_df)), 'semantic_score')
    
    for idx, (i, row) in enumerate(top_samples.iterrows(), 1):
        print(f"[{idx}] Score: {row['semantic_score']:.2f} | Source: {row['source']} | File: {row['filename']}")
        text_preview = row['text'][:300].replace('\n', ' ')
        print(f"    {text_preview}...")
        print()

# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================
def main():
    print(f"\n{'#'*70}")
    print(f"# PIPELINE 2: SEMANTIC FILTERING FOR UNCERTAINTY TOPICS")
    print(f"{'#'*70}\n")
    
    # Step 0: æ¸…ç©ºæ—§ç»“æœ â­ æ–°å¢
    clean_previous_results()
    
    # Step 1: è¯»å–æ–‡æœ¬
    df = read_text_files(INPUT_FOLDERS)
    
    if len(df) == 0:
        print("âŒ No texts found! Please check input folders.")
        print(f"\n   Expected folders:")
        for folder in INPUT_FOLDERS:
            print(f"   - {folder}/")
        return
    
    # Step 2: è¯­ä¹‰è¿‡æ»¤
    filtered_df, all_df = filter_texts(df, threshold=THRESHOLD)
    
    # Step 3: ä¿å­˜è¿‡æ»¤åçš„æ–‡æœ¬
    save_filtered_texts(filtered_df, OUTPUT_FOLDER)
    
    # Step 4: ä¿å­˜ç»Ÿè®¡å’Œå¯è§†åŒ–
    save_statistics(filtered_df, all_df, STATS_FOLDER)
    
    # Step 5: æ˜¾ç¤ºæ ·æœ¬
    print_sample_texts(filtered_df, n_samples=5)
    
    # æ€»ç»“
    print(f"\n{'#'*70}")
    print(f"# FILTERING COMPLETED SUCCESSFULLY")
    print(f"{'#'*70}")
    print(f"\nğŸ“ Output folders:")
    print(f"   - Filtered texts: {OUTPUT_FOLDER}/")
    print(f"   - Statistics:     {STATS_FOLDER}/")
    print(f"\nğŸ¯ Next step: Run pipeline_3_cluster.py for clustering\n")

if __name__ == "__main__":
    main()
